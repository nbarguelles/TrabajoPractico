Dudas Ejercicio 1 del practico 1.

Tengo muchas dudas con el tema de las métricas de evaulación del modelo. Cuando hicimos el ejercicio en clase usamos el codigo 

model.compile(loss="binary_crossentropy", optimizer="rmsprop", metrics=[tf.keras.metrics.Accuracy()])

Entiendo que estamos tomando cómo métrica la accuracy, pero eso es lo mismo que calculamos de la matriz de confusión 
Accuracy = Predicciones correctas / Predicciones totales? O que es esa accuracy. 

Adjunto un archivo donde le hice captura a un entrenamiento y la gráfica de la función loss me da (creo) bastante bien y la matriz de confusión también (calculo una accuracy= 0.9) pero la gráfica del accuracy del modelo me da fea y en ningún momento toma valores superiores al 0.1

En resumen, no entiendo bien que es lo que calcula esta parte del código
 metrics=[tf.keras.metrics.Accuracy()]

Por otro lado, estuve googleando sobre las metrics y vi que puedo escribir así 

model.compile(loss="binary_crossentropy", optimizer="rmsprop", metrics=["accuracy"])

donde entiendo que tambien le digo al modelo que tome como metrica la accuracy pero da resultados completamente distintos que la otra linea de código. Cuando entrené el modelo con esta métrica, con la matriz de confusión calculo una accuracy = 0.765 y la gráfica del accuracy llega hasta valores de 0.8 lo cual me parece más coherente. 

De todas formas capaz que no tiene nada que ver una cosa con la otra. 

Cómo se debería ver un gráfico de accuracy para que sea un buen entrenamiento? Según mi intuición se debería ver como me dio en el segundo entrenamiento pero en ese caso no me dio bien la matriz de confusión.
